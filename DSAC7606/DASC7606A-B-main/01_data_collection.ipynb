{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Stage 1: Data Collection and Exploration\n",
    "\n",
    "**Welcome to the first stage of your deep learning journey!** In this notebook, we'll lay the foundation for our image classification project by acquiring and thoroughly understanding our dataset. A deep understanding of the data is crucial for building effective models.\n",
    "\n",
    "### üéØ Objectives for this Stage:\n",
    "\n",
    "- **Download and Load**: Use `torchvision` to efficiently acquire the CIFAR-10 dataset.\n",
    "- **Explore Structure**: Understand the dataset's components, size, and format.\n",
    "- **Visualize Samples**: Look at images from each class to build intuition about the data.\n",
    "- **Analyze Distribution**: Check the balance of classes to identify potential biases.\n",
    "\n",
    "### üîç Why This Stage Matters\n",
    "\n",
    "The principle of **\"Garbage in, garbage out\"** is fundamental in machine learning. The quality of our model is capped by the quality of our data. By meticulously analyzing the dataset now, we can:\n",
    "\n",
    "- Make informed decisions about data preprocessing and augmentation.\n",
    "- Identify and mitigate potential issues early on.\n",
    "- Develop a strong intuition for the classification challenge ahead.\n",
    "\n",
    "---\n",
    "\n",
    "**Let's begin by setting up our environment and importing the necessary tools!** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Importing Libraries and Preparing the Environment\n",
    "\n",
    "First, we'll import the essential libraries for data handling, visualization, and file operations. We'll also create the necessary directories to store our raw data, ensuring our project stays organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries for data manipulation and visualization\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Custom script for handling the download process\n",
    "from scripts.data_download import download_and_extract_cifar10_data, download_and_extract_cifar100_data\n",
    "\n",
    "# Create the directory for our raw data if it doesn't already exist\n",
    "print(\"Preparing data directory...\")\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "print(\"Setup complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition: Downloading the CIFAR-10 Dataset\n",
    "\n",
    "Now that our environment is ready, let's download the CIFAR-10 dataset. We are using a helper function from our `scripts` directory which handles the download and initial loading into PyTorch `Dataset` objects. This will provide us with two separate datasets: one for training our model and one for testing its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = download_and_extract_cifar10_data()\n",
    "# train_dataset, test_dataset = download_and_extract_cifar100_data()\n",
    "\n",
    "print(f\"Training dataset contains {len(train_dataset)} images.\")\n",
    "print(f\"Test dataset contains {len(test_dataset)} images.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "With the data loaded, our next step is to explore it. EDA helps us understand the characteristics of our dataset, which is vital for building an effective model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Visualizing Image Samples\n",
    "\n",
    "Let's visualize a few random images from our training set along with their corresponding labels. This gives us a qualitative feel for the image quality, object variety, and overall complexity of the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classes in the CIFAR-10 dataset\n",
    "classes = train_dataset.classes\n",
    "\n",
    "def imshow(img):\n",
    "    \"\"\"Helper function to un-normalize and display an image.\"\"\"\n",
    "    # The ToTensor transform scales images to [0,1], we'll display them as such\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Create a DataLoader to fetch a small batch of random training images\n",
    "data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "images, labels = next(iter(data_loader))\n",
    "\n",
    "# Show the images in a grid\n",
    "print(\"Displaying a random batch of 8 images from the training set:\")\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# Print the corresponding labels\n",
    "print('Labels: ', ' '.join(f'{classes[labels[j]]:10s}' for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Analyzing Class Distribution\n",
    "\n",
    "Next, let's check if the dataset is **balanced**. A balanced dataset has a roughly equal number of samples for each class. If a significant imbalance exists, a model might become biased towards the more frequent classes. We'll plot the number of images per class for both the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(dataset, title):\n",
    "    \"\"\"Calculates and plots the distribution of classes in a dataset.\"\"\"\n",
    "    # Count occurrences of each class\n",
    "    class_counts = {class_name: 0 for class_name in classes}\n",
    "    # The targets attribute in torchvision datasets holds the labels\n",
    "    for label in dataset.targets:\n",
    "        class_counts[classes[label]] += 1\n",
    "\n",
    "    class_names = list(class_counts.keys())\n",
    "    counts = list(class_counts.values())\n",
    "\n",
    "    # Create the bar plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(class_names, counts, color=plt.cm.viridis(np.linspace(0, 1, len(classes))))\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.ylabel(\"Number of Images\", fontsize=12)\n",
    "    plt.xlabel(\"Class\", fontsize=12)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add count labels on top of bars\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2.0, yval, int(yval), va='bottom', ha='center')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot for both training and test sets\n",
    "plot_class_distribution(train_dataset, \"Training Set Class Distribution\")\n",
    "plot_class_distribution(test_dataset, \"Test Set Class Distribution\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The plots confirm that the CIFAR-10 dataset is perfectly balanced, with exactly 5,000 training images and 1,000 testing images per class. This is excellent, as it means we don't need to worry about class imbalance techniques like oversampling or weighted loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Stage 1 Complete: Next Steps\n",
    "\n",
    "Excellent work! We have successfully completed the first stage of our project.\n",
    "\n",
    "**What we've accomplished:**\n",
    "1.  **Set up** our environment and libraries.\n",
    "2.  **Downloaded** and loaded the CIFAR-10 training and test datasets.\n",
    "3.  **Visualized** sample images to understand their content and quality.\n",
    "4.  **Analyzed** the class distribution and confirmed that the dataset is balanced.\n",
    "\n",
    "With this solid foundation, we are now ready to move on to **Stage 2: Data Preprocessing**, where we will prepare this raw data for training our neural network."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.14.5"
   }
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
