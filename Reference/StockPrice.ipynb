{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe24f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155770b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b24fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af413d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "\n",
    "url = 'https://www.hkex.com.hk/eng/services/trading/securities/securitieslists/ListOfSecurities.xlsx'\n",
    "try:\n",
    "    response = requests.get(url, timeout=10.0)\n",
    "    response.raise_for_status()\n",
    "except requests.RequestException as e:\n",
    "    raise SystemExit(f\"Error, {url} is not available: {e}\")\n",
    "\n",
    "hk_stk = pd.read_excel(io.BytesIO(response.content), skiprows=2, dtype={'Stock Code': str}, index_col= 'Stock Code')\n",
    "hk_stk = hk_stk[(hk_stk.index.astype(int)<10000) & (hk_stk['Category'] == 'Equity')]\n",
    "hk_stk.rename(index=lambda x: x[-4:] +'.HK', inplace=True)\n",
    "hk_stk.index.name= 'Ticker'\n",
    "hk_stk['exchange'] = 'HKG'\n",
    "hk_stk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40df79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import requests\n",
    "\n",
    "STOCK_SOURCES = {\n",
    "    'ASE': 'https://raw.githubusercontent.com/rreichel3/US-Stock-Symbols/refs/heads/main/amex/amex_full_tickers.json',\n",
    "    'NMS': 'https://raw.githubusercontent.com/rreichel3/US-Stock-Symbols/refs/heads/main/nasdaq/nasdaq_full_tickers.json',\n",
    "    'NYQ': 'https://raw.githubusercontent.com/rreichel3/US-Stock-Symbols/refs/heads/main/nyse/nyse_full_tickers.json',\n",
    "}\n",
    "\n",
    "def fetch_exchange_data(name, url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10.0)\n",
    "        response.raise_for_status()\n",
    "        df = pd.read_json(BytesIO(response.content)).reset_index(drop=True).set_index('symbol')\n",
    "        df.index.name = 'Ticker'\n",
    "        df['exchage']= name\n",
    "        return df\n",
    "    except requests.RequestException as e:\n",
    "        raise SystemExit(f'Failed to fetch{name} data : {e}')\n",
    "    \n",
    "us_stk = pd.concat([fetch_exchange_data(name, url) for name , url in STOCK_SOURCES.items()])\n",
    "us_stk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27808177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "stk_list = hk_stk.index.tolist() + us_stk.index.tolist()\n",
    "#stk_list =  us_stk.index.tolist()\n",
    "\n",
    "stk_price = yf.download(tickers=stk_list, period='1y', group_by='ticker', actions=True, threads=True).stack(level=0).reindex()\n",
    "\n",
    "stk_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea71c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Download daily history for a (potentially large) list of tickers from both\n",
    "Hong Kong and U.S. markets, using yfinance in manageable batches.\n",
    "\n",
    "Author : chi\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import itertools\n",
    "from typing import Iterable, List\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Configuration\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "BATCH_SIZE   = 25            # yfinance becomes flaky with >50-75 symbols / call\n",
    "DOWNLOAD_KW  = dict(         # default yfinance options; tweak as you wish\n",
    "    period   = \"5y\",\n",
    "    group_by = \"ticker\",\n",
    "    actions  = True,\n",
    "    threads  = True,\n",
    "    auto_adjust = True,\n",
    ")\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Utilities\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def chunked(iterable: Iterable[str], size: int) -> Iterable[List[str]]:\n",
    "    \"Yield lists of at most *size* items from *iterable*.\"\n",
    "    iterator = iter(iterable)\n",
    "    while (batch := list(itertools.islice(iterator, size))):\n",
    "        yield batch\n",
    "\n",
    "\n",
    "def unique_order_preserved(seq: Iterable[str]) -> List[str]:\n",
    "    \"Return a list with duplicates removed, keeping first-occurrence order.\"\n",
    "    seen: set[str] = set()\n",
    "    return [x for x in seq if not (x in seen or seen.add(x))]\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Core logic\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def download_history(tickers: List[str],\n",
    "                     *,\n",
    "                     batch_size: int = BATCH_SIZE,\n",
    "                     **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch OHLCV history for *tickers* in successive batches.\n",
    "\n",
    "    Returns a tidy DataFrame indexed by ['Date', 'Ticker'].\n",
    "    \"\"\"\n",
    "    opts = {**DOWNLOAD_KW, **kwargs}\n",
    "    frames: list[pd.DataFrame] = []\n",
    "\n",
    "    for batch in chunked(tickers, batch_size):\n",
    "        try:\n",
    "            raw = yf.download(tickers=batch, **opts)          # Multi-column wide form\n",
    "        except Exception as exc:                       # network hiccup, etc.\n",
    "            print(f\"âš ï¸  batch {batch[:3]}â€¦ failed: {exc}\")\n",
    "            continue\n",
    "\n",
    "        if raw.empty:\n",
    "            print(f\"âš ï¸  batch {batch[:3]}â€¦ returned no data\")\n",
    "            continue\n",
    "\n",
    "        frames.append(raw)\n",
    "\n",
    "    if not frames:\n",
    "        raise RuntimeError(\"No data fetched for any ticker.\")\n",
    "\n",
    "    # wide â†’ long; put 'Ticker' in index level 1, preserve data columns level 2\n",
    "    df = (pd.concat(frames, axis=1)\n",
    "            .stack(level=0)                # (Date, DataColumn) Ã— Ticker â†’ (Date, Ticker) index\n",
    "            .swaplevel(0, 1)               # want (Date, Ticker) not (Ticker, Date)\n",
    "            .sort_index()\n",
    "            .rename_axis(index=[\"Ticker\", \"Date\"])\n",
    "            .sort_index())\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_ticker_list(us_df: pd.DataFrame, hk_df: pd.DataFrame) -> List[str]:\n",
    "    \"Merge HK and US ticker indices into a de-duplicated, deterministic list.\"\n",
    "    return unique_order_preserved(us_df.index.tolist() + hk_df.index.tolist())\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Public entry point\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def get_full_price_history(hk_stk: pd.DataFrame,us_stk: pd.DataFrame, **download_kw) -> pd.DataFrame:\n",
    "#def get_full_price_history(us_stk: pd.DataFrame, **download_kw) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convenience wrapper: deduplicate tickers and call yfinance downloader.\n",
    "    \"\"\"\n",
    "    tickers = build_ticker_list(us_stk, hk_stk)\n",
    "    print(f\"ðŸ“ˆ Downloading history for {len(tickers)} symbols â€¦\")\n",
    "    return download_history(tickers, **download_kw)\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Example usage (uncomment for quick test)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "stk_price = get_full_price_history(hk_stk, us_stk)\n",
    "stk_price.to_parquet(\"data/full_prices.parquet\", compression=\"gzip\", index=False)\n",
    "print(stk_price.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde4ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stk_price.to_parquet(\"data/full_prices.parquet\", compression=\"gzip\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb581cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stk_price.to_parquet(\"data/full_prices.parquet\", index=False, engine='pyarrow', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9776bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Dict, List, Sequence\n",
    "\n",
    "\n",
    "def fetch_info(ticker: str) -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Grab Yahoo 'info' for a single ticker.\n",
    "    Strips the huge 'companyOfficers' blob.\n",
    "    Returns a minimal placeholder dict if the call fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        info: Dict[str, object] = {k: v for k, v in yf.Ticker(ticker).info.items() if isinstance(v, list)==False} or {} #yf.Ticker(ticker).info or {}\n",
    "    except Exception as exc:                 # network hiccup, bad symbol, â€¦\n",
    "        return {\"Ticker\": ticker, \"_error\": str(exc)}\n",
    "\n",
    "    #info.pop(\"companyOfficers\", None)        # drop if present\n",
    "    info[\"Ticker\"] = ticker\n",
    "    return info\n",
    "\n",
    "\n",
    "def build_metadata_frame(\n",
    "    tickers: Sequence[str],\n",
    "    max_workers: int = 16,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parallel-download metadata for all tickers and return a tidy DataFrame.\n",
    "    \"\"\"\n",
    "    rows: List[Dict[str, object]] = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as pool:\n",
    "        futures = {pool.submit(fetch_info, t): t for t in tickers}\n",
    "        for fut in as_completed(futures):\n",
    "            rows.append(fut.result())        # each result is a dict\n",
    "\n",
    "    return pd.DataFrame.from_records(rows).set_index(\"Ticker\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Usage\n",
    "# ---------------------------------------------------------------------\n",
    "tickers = hk_stk.index.tolist() + us_stk.index.tolist()\n",
    "df = build_metadata_frame(tickers)\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
